<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon/favicon_io/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/favicon_io/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon/favicon_io/favicon-16x16.png">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.28/fancybox/fancybox.css" integrity="sha256-6cQIC71/iBIYXFK+0RHAvwmjwWzkWd+r7v/BX3/vZDc=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"saicat.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="【本文已在同名 微信公众号 &#x2F; 知乎 &#x2F; 个人博客linsight.cn 上线】  01.AI（零一万物），是李开复带队孵化的AI公司。2023年11月初，01.AI发布并开源了Yi-6B、Yi-34B base模型，同一周内，又开源了Yi-6B-200K和Yi-34B-200K base模型。Yi号称是从零预训练的双语模型。接下来的几个月，01.AI陆续推出了chat模型、多模态能力，Yi-9B">
<meta property="og:type" content="article">
<meta property="og:title" content="Yi技术报告-划重点看细节">
<meta property="og:url" content="https://saicat.github.io/41b6a819.html">
<meta property="og:site_name" content="Linsight">
<meta property="og:description" content="【本文已在同名 微信公众号 &#x2F; 知乎 &#x2F; 个人博客linsight.cn 上线】  01.AI（零一万物），是李开复带队孵化的AI公司。2023年11月初，01.AI发布并开源了Yi-6B、Yi-34B base模型，同一周内，又开源了Yi-6B-200K和Yi-34B-200K base模型。Yi号称是从零预训练的双语模型。接下来的几个月，01.AI陆续推出了chat模型、多模态能力，Yi-9B">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://saicat.github.io/41b6a819/eval.png">
<meta property="og:image" content="https://saicat.github.io/41b6a819/model.png">
<meta property="og:image" content="https://saicat.github.io/41b6a819/cover.png">
<meta property="og:image" content="https://saicat.github.io/41b6a819/pretrain_data_pipeline.png">
<meta property="og:image" content="https://saicat.github.io/41b6a819/pretrain_data_dist.png">
<meta property="og:image" content="https://saicat.github.io/41b6a819/sft.png">
<meta property="og:image" content="https://saicat.github.io/41b6a819/base_model_eval.png">
<meta property="og:image" content="https://saicat.github.io/41b6a819/ict.png">
<meta property="og:image" content="https://saicat.github.io/41b6a819/eval.png">
<meta property="og:image" content="https://saicat.github.io/41b6a819/third_party.png">
<meta property="og:image" content="https://saicat.github.io/41b6a819/long_context_result.png">
<meta property="og:image" content="https://saicat.github.io/41b6a819/multimodal.png">
<meta property="og:image" content="https://saicat.github.io/41b6a819/9B.png">
<meta property="og:image" content="https://saicat.github.io/images/qrcode.jpg">
<meta property="article:published_time" content="2024-03-26T08:51:08.000Z">
<meta property="article:modified_time" content="2024-03-29T11:53:37.115Z">
<meta property="article:author" content="Lin">
<meta property="article:tag" content="多模态">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="transformer">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="长上下文">
<meta property="article:tag" content="技术报告">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://saicat.github.io/41b6a819/eval.png">


<link rel="canonical" href="https://saicat.github.io/41b6a819.html">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://saicat.github.io/41b6a819.html","path":"41b6a819.html","title":"Yi技术报告-划重点看细节"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Yi技术报告-划重点看细节 | Linsight</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Linsight</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">聊聊技术，也聊聊其他的</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#tldr"><span class="nav-number">1.</span> <span class="nav-text">TL;DR</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.</span> <span class="nav-text">模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A7%84%E6%A8%A1%E9%80%89%E6%8B%A9"><span class="nav-number">2.1.</span> <span class="nav-text">规模选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="nav-number">2.2.</span> <span class="nav-text">模型结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tokenizer"><span class="nav-number">2.3.</span> <span class="nav-text">tokenizer</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE"><span class="nav-number">3.</span> <span class="nav-text">数据</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE"><span class="nav-number">3.1.</span> <span class="nav-text">预训练数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BE%AE%E8%B0%83%E6%95%B0%E6%8D%AE"><span class="nav-number">3.2.</span> <span class="nav-text">微调数据</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83"><span class="nav-number">4.</span> <span class="nav-text">训练</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#infra"><span class="nav-number">4.1.</span> <span class="nav-text">infra</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83"><span class="nav-number">4.2.</span> <span class="nav-text">预训练</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BE%AE%E8%B0%83"><span class="nav-number">4.3.</span> <span class="nav-text">微调</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B"><span class="nav-number">5.</span> <span class="nav-text">模型评测</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B"><span class="nav-number">5.1.</span> <span class="nav-text">基模型评测</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#chat%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B"><span class="nav-number">5.2.</span> <span class="nav-text">Chat模型评测</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%83%BD%E5%8A%9B%E6%89%A9%E5%B1%95"><span class="nav-number">6.</span> <span class="nav-text">能力扩展</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E8%83%BD%E5%8A%9B"><span class="nav-number">6.1.</span> <span class="nav-text">长上下文能力</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81"><span class="nav-number">6.2.</span> <span class="nav-text">多模态</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#depth-upscaling-%E6%B7%B1%E5%BA%A6%E6%89%A9%E5%B1%95"><span class="nav-number">6.3.</span> <span class="nav-text">Depth Upscaling 深度扩展</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Lin"
      src="/images/avatar/Picasso_Elephant.png">
  <p class="site-author-name" itemprop="name">Lin</p>
  <div class="site-description" itemprop="description">AI | NLP</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">73</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">70</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="mailto:331603034@qq.com" title="E-Mail → mailto:331603034@qq.com" rel="noopener me" target="_blank"><i class="fa-regular fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

<!--
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/1.js?i=5acfv0hqzp5&amp;s=220&amp;m=1&amp;v=false&amp;r=false&amp;b=000000&amp;n=false&amp;c=ff0000" async="async"></script>
-->

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://saicat.github.io/41b6a819.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar/Picasso_Elephant.png">
      <meta itemprop="name" content="Lin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Linsight">
      <meta itemprop="description" content="AI | NLP">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Yi技术报告-划重点看细节 | Linsight">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Yi技术报告-划重点看细节
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-03-26 16:51:08" itemprop="dateCreated datePublished" datetime="2024-03-26T16:51:08+08:00">2024-03-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-29 19:53:37" itemprop="dateModified" datetime="2024-03-29T19:53:37+08:00">2024-03-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/CS/" itemprop="url" rel="index"><span itemprop="name">CS</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/CS/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/CS/NLP/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>16 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>【本文已在同名 微信公众号 / 知乎 / <a target="_blank" rel="noopener" href="http://www.linsight.cn/">个人博客linsight.cn</a> 上线】</p>
<hr>
<p>01.AI（零一万物），是李开复带队孵化的AI公司。2023年11月初，01.AI发布并开源了Yi-6B、Yi-34B
base模型，同一周内，又开源了Yi-6B-200K和Yi-34B-200K
base模型。Yi号称是从零预训练的双语模型。接下来的几个月，01.AI陆续推出了chat模型、多模态能力，Yi-9B、长上下文的记忆和检索能力等优化。</p>
<p>从2023年11发布起，个人就有测试和使用Yi的模型。在SuperCLUE/CMMLU等一些榜单数据的实测上，发现Yi的效果确实不错。实际工作使用里，Yi的效果基本也都能排在同时期中文（开源）大模型里的第一梯队。</p>
<p>2024年3月，Yi终于发布了技术报告，在此来梳理一下报告中的重点内容和值得关注的细节信息。</p>
<h1 id="tldr">TL;DR</h1>
<p>先给出核心内容的总结：</p>
<ul>
<li>Yi-34B模型int4量化之后，相比float16损失&lt;1%，可以跑在RTX4090上（24G显存）</li>
<li>模型结构不需要太多变化，LLAMA2标准结构已经足够训出很好的效果</li>
<li>3.1T的预训练数据远比scaling
law建议的1T大，但是效果更好，并且模型还没饱和，继续增大数据量还能提升</li>
<li>微调数据质量很重要，由算法人员直接标注，只要&lt;10k的数据量就足够了</li>
<li>4k长度的基础预训练模型已经具备长文本能力，只需用长文本数据继续预训练，更新百步就有很好效果</li>
<li>总之，数据要精心设计，数据质量要高，数据量要大</li>
</ul>
<h1 id="模型">模型</h1>
<h2 id="规模选择">规模选择</h2>
<p>Yi目前有6B、9B、34B三个规模，其中34B是主力模型。</p>
<p>选择34B，而不是更大规模的原因，是这个规模能在24G显存的消费级显卡（如RTX4090）上运行。</p>
<p>使用int4量化之后的34B模型可以运行在24G显存的GPU上。</p>
<p>参考<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2301.12017">《Understanding INT4
Quantization for Language Models: Latency Speedup, Composability, and
Failure
Cases》</a>的量化方法，Yi-34B的int8量化模型相比bf16模型，几乎可以做到效果无损（差距&lt;1%），而int4量化模型在大部分任务的损失也完全可以接受，具体效果如下表。</p>
<img src="/41b6a819/eval.png" class title="Yi效果">
<p>训练数据总共是3.1T token，这比DeepMind的scaling
law所建议的1TB要大不少。目前能接触到的这个规模的模型，数据量基本都&lt;2T。</p>
<p>（即提出Chinchilla模型的<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.15556">《Training Compute-Optimal Large
Language Models》</a>的scaling law）</p>
<p>也就是从scaling law的角度来说，Yi是overtrain的。</p>
<p><big><strong>但是Yi实践结果证明，较小模型+更大规模的高质量数据，是可以获得进一步效果提升的，这也就让我们获得了高性价比的推理模型--34B推理成本+大训练投入，就能得到接近普通70B规模的推理效果。</strong></big></p>
<h2 id="模型结构">模型结构</h2>
<p>结构上，基于标准LLAMA2模型，做了一些变化</p>
<ul>
<li>注意力机制：LLAMA2只在70B用了GQA，Yi全系列都用了GQA，具体参数如下表<br>
</li>
<li>位置编码：RoPE，参考RoPE ABF（《Effective long-context scaling of
foundation models》），base扩大到10M，用于支持长上下文。<br>
</li>
<li>激活函数：使用SwiGLU，参考《GLU Variants Improve Transformer》</li>
</ul>
<p>并且把activation
size从4h降为8/3h，这里的说法是补偿了GQA带来的参数下降</p>
<blockquote>
<p>We use SwiGLU as Yi’s post-attention layer, reducing its activation
size from 4h to 8/3h (h denotes hidden size) to be consistent with the
normal post-attention layer. This adjustment also compensates for the
reduction in parameter resulted from GQA, making the overall parameter
count comparible of existing 7B and 34B models.</p>
</blockquote>
<img src="/41b6a819/model.png" class title="Yi模型结构">
<p>关于模型结构，一个结论就是<big><strong>“虽然做了很多模型结构上的实验，但是最终发现，标准的结构就足以训出足够好的模型”</strong></big></p>
<h2 id="tokenizer">tokenizer</h2>
<ul>
<li>用BPE，词表大小为64000，这个大小平衡了计算效率和表达能力；<br>
</li>
<li>其中数字全是单个的digit，让模型能更好地理解数字数据；<br>
</li>
<li>对于OOV的词，会降级用unicode编码 ；</li>
<li>保留全角标点符号，不转为半角；</li>
</ul>
<p>另外，优先考虑英语的LLM在tokenizer会使用虚拟前缀（文本开头的空格）来泛化句子不同位置相同的单词。Yi不这么做，因为即使是在英语语境中，这种假设并不总是成立，比如对于以引号开头的句子，而且在中文语境中，这么做没有明显效果。</p>
<h1 id="数据">数据</h1>
<p>数据，是LLM最核心的部分，没有之一。Yi最核心的工作就是提升数据数量和质量。</p>
<img src="/41b6a819/cover.png" class title="数据">
<h2 id="预训练数据">预训练数据</h2>
<p>预训练数据整体处理流程如下</p>
<img src="/41b6a819/pretrain_data_pipeline.png" class title="预训练数据处理流程">
<ol type="1">
<li>语料获取 &amp; 语言分类</li>
</ol>
<p>从网络爬虫开始，爬取中英文这两种语言的网站，对网站内容进行解析。</p>
<p>并参考CCNeT（《CCNet: Extracting High Quality Monolingual Datasets
from Web Crawl Data》）的做法，进行语言识别。</p>
<ol start="2" type="1">
<li>规则过滤器 Heuristic Rule Filters</li>
</ol>
<p>目的是快速过滤掉明显的低质量数据。基于这些规则来过滤掉：</p>
<ul>
<li>URL、域名、单词黑名单和乱码文本；<br>
</li>
<li>文档长度、特殊符号的比例，以及短行、连续行或不完整行的比例；<br>
</li>
<li>重复的单词模式、n-gram或段落，参考《Scaling Language Models:
Methods, Analysis &amp; Insights from Training
Gopher》的做法，阈值则是来参考《CulturaX: A Cleaned, Enormous, and
Multilingual Dataset for Large Language Models in 167 Languages》；</li>
<li>数据脱敏：识别并匿名化个人信息（Personal Identifiable
Information，PII），如电子邮件地址和电话号码。</li>
</ul>
<ol start="3" type="1">
<li>可训练过滤器 Learned Filters</li>
</ol>
<p>对于不好用规则处理的，就用模型来学习模式，并进行清洗。共有4个scorer：</p>
<ul>
<li>Perplexity Scorer：参照《CCNet: Extracting High Quality Monolingual
Datasets from Web Crawl
Data》，用kenlm库，把高于平均perplexity的内容丢弃；</li>
<li>Quality
Scorer：识别如维基百科这样的高质量内容，丢弃低质量内容；</li>
<li>Document Coherence
Scorer：用于发现句子、段落零散不连贯的文本，要么分割，要么直接丢弃；</li>
<li>Safety Scorer：识别并删除暴力、色情、涉政内容</li>
</ul>
<ol start="4" type="1">
<li>基于聚类的过滤 Cluster-based Filters</li>
</ol>
<p>用聚类的方法，把所有文档进行分类。一方面用于给数据混合策略做参考，一方面如果整个类别的质量太差，就直接抛弃类别内的所有数据。</p>
<ol start="5" type="1">
<li>去重</li>
</ol>
<p>参考《The RefinedWeb Dataset for Falcon LLM: Outperforming Curated
Corpora with Web Data, and Web Data
Only》，做文档级的minhash去重，以及子文档级的完全匹配去重。</p>
<p>最终获得的数据分布如下</p>
<img src="/41b6a819/pretrain_data_dist.png" class title="预训练数据分布">
<p>虽然数据规模一定要够，但是也不能因此就放弃数据质量，否则只能是garbage
in，garbage out</p>
<blockquote>
<p>we prefer 3T tokens over sophasticated engineering over 10T tokens
without extensive filtering</p>
</blockquote>
<p>这句话大概表示清洗前的数据有10T，这也是一个信息，符合质量的数据可能只有3成</p>
<h2 id="微调数据">微调数据</h2>
<p>对于微调数据，一句话：Quality is All You Need。</p>
<p>一共只有&lt;10k条SFT数据，每条数据都通过人工多次打磨，这比大数量但质量一般的数据的效果好。</p>
<p>这思路和《Gemini: A family of highly capable multimodal
models.》、《Llama 2: Open Foundation and Fine-Tuned Chat
Models》、《Lima: Less is more for alignment》一致，而和FLAN（《Scaling
instruction-finetuned language models》）以及UltraChat（《Enhancing chat
language models by scaling high-quality instructional
conversations》）这样更关注数据量的做法不同。</p>
<p>具体做法上有：</p>
<ul>
<li>对于<big><strong>prompt distribution
selection</strong></big>：参考《Wizardlm: Empowering large language
models to follow complex
instructions》，开发复合指令，并通过指令进化，逐步增加指令的复杂度。这种做法显著减少了SFT数据量。<br>
</li>
<li>对于<big><strong>CoT data formatting</strong></big>：参考《Take a
step back: Evoking reasoning via abstraction in large language
models》，采用了“Step-Back”的模式。即通过抽象化处理，让模型学习在深入探讨原始、具体的问题之前，制定更高层次的解决方案。<br>
</li>
<li>对于<big><strong>response formatting</strong></big>：使用从《Lima:
Less is more for
alignment》扩展的默认样式。总体而言，response的结构为introduction-body-conclusion的格式，“where
the body is usually a list of bullet point”。<br>
</li>
<li>在缓解<big><strong>幻觉</strong></big>问题上，思路是确保response中的知识不由模型内部产生，对应的做法是把会导致模型进行记忆的response删掉。（但是这个具体标准是什么，有没有了解的朋友说下看法？）<br>
</li>
<li>在缓解<big><strong>生成重复</strong></big>的问题上，则是直接把response中包含重复的部分都重写了。（核心还是洗数据，一条条打磨）<br>
</li>
<li>数据<big><strong>多样性</strong></big>很重要，因此参考《#instag:
Instruction tagging for analyzing supervised fine-tuning of large
language
models》建立了一个打标系统，并设计一个注重多样性的采样算法，平衡了各个领域数据的分布。<br>
</li>
<li>为了找到最佳的数据<big><strong>配比</strong></big>，参考《How
abilities in large language models are affected by supervised
fine-tuning data composition》，使用近似网络搜索（approximate grid
search），对每个领域以{1, 1/2, 1/4, 1/8, 1/16, 1/32,
1/64}的比例进行实验和人工测评，找到最佳的组合方式。<br>
</li>
<li>除了内容，<big><strong>数据格式</strong></big>对效果也有很大影响。参OPENAI的ChatML格式（<a target="_blank" rel="noopener" href="https://github.com/openai/openai-python/blob/e389823ba013a24b4c32ce38fa0bd87e6bccae94/chatml.md">https://github.com/openai/openai-python/blob/e389823ba013a24b4c32ce38fa0bd87e6bccae94/chatml.md</a>），这种结构化的格式使模型能够区分各种信息类型，如system
prompt、user input和bot response。</li>
</ul>
<p>SFT数据质量能极大影响模型的效果，随着数据量的增加，高质量数据能带来更多提升，如下图</p>
<img src="/41b6a819/sft.png" class title="SFT">
<h1 id="训练">训练</h1>
<h2 id="infra">infra</h2>
<p>从数据处理到模型训练都需要大集群大算力的支持。Yi构建了支持全栈数据处理、预训练、微调和服务的基础设施。包括：</p>
<ol type="1">
<li>自动管理和监控计算资源的能力；</li>
<li>通过优化并行策略、内核效率和长上下文支持提高训练速度；</li>
<li>统一微调框架，支持异构分布式训练后端，例如在DPO中同时使用Megatron和DeepSpeed进行多个模型的训练；</li>
<li>通过各种LLM服务加速技术（如量化、continuous batching 和 paged
attention）降低部署成本。</li>
</ol>
<p>总之这部分工作还是很多的，比如由于经常有硬件坏，坏的硬件会被自动从资源池移除；任务失败时，会自动跟踪重启。给算法人员考法UI等。</p>
<h2 id="预训练">预训练</h2>
<p>训了4k基础模型。（暂时没有给出更多细节）</p>
<h2 id="微调">微调</h2>
<p>超参如下</p>
<ul>
<li>AdamW：beta=[0.9,0.999]，epsilon = 1e-8<br>
</li>
<li>seq_len = 4096<br>
</li>
<li>batch size = 64<br>
</li>
<li>constant lr = 1e-5，weight decay = 0.1<br>
</li>
<li>gradient clip = 1.0<br>
</li>
<li>max step = 300</li>
<li>参考《Neftune: Noisy embeddings improve instruction
finetuning》，对于6B模型 noise scale = 5，对于34B模型 noise scale =
45</li>
</ul>
<h1 id="模型评测">模型评测</h1>
<h2 id="基模型评测">基模型评测</h2>
<ol type="1">
<li>基础能力评测</li>
</ol>
<p>对其他开源模型，保持和公开的设置相同做法获取结果。Yi使用贪婪解码，没有进行任何后处理，结果如下表</p>
<img src="/41b6a819/base_model_eval.png" class title="Base模型效果">
<p>在数学和代码能力上，和GPT3.5、GPT4还存在一些差距，而这些能力是可以通过继续预训练和微调来持续提升的。Yi最初的设计并没有针对这些能力，因此没有在预训练数据中包含特别多相关数据，后续会有计划增加这部分能力的提升。</p>
<p>而和其他开源模型相比，在代码和数学以外的任务，Yi基本上做到了跟大一倍模型的效果相近，甚至更好的水平。</p>
<ol start="2" type="1">
<li>观察</li>
</ol>
<ul>
<li>模型规模带来的增益：尽管Yi-34B和Yi-6B使用了相同的预训练语料，但Yi-34B的性能相比Yi-6B有了质的提升。更大的模型尺寸在代码和数学基准测试上带来了明显的增益。<br>
</li>
<li>数据质量：高质量预训练数据的小型模型，如Yi-34B或Qwen-14B，通常表现优于尺寸更大但（可能）数据质量较低的模型，例如Falcon-180B。</li>
<li>GPT-4与开源LLM之间的差距：开源LLM在多种基准测试上的性能仍然落后于GPT-4和GPT-3.5。然而，具有代表性的双语LLM，例如Qwen-14B和Yi-34B，可以在包括C-Eval、CMMLU和Gaokao在内的中文知识相关基准测试上匹配甚至超过GPT-4的性能。然而，在BBH、代码（HumanEval）和数学（MATH）等推理相关基准测试上，仍然存在巨大的差距。</li>
</ul>
<ol start="3" type="1">
<li>In-Context Learning能力的测试</li>
</ol>
<p>Yi进一步研究了in-context
learning的能力，即根据少数展示的输入-输出示例，推断underlying
function的能力。</p>
<p>考虑的任务是推断加权和的线性系数。具体来说，定义 y = w1x1 + w2x2 +
... + wnxn。</p>
<p>少量示例展示是 x1, x2, ..., xn, y，要求模型预测给定一组新输入 x 的
y。</p>
<p>这就要求模型隐式地推断出 w1, w2, ..., wn。</p>
<p>评测上，使用（a）模型预测的 y 与真实值 y∗ 之间的绝对差，即 |y − y∗|
作为连续度量，以及使用（b）精确匹配 y == y∗ 作为不连续度量。</p>
<p>模型在算术上的效果正常，因此可以认为这样的测试不受算术能力的影响，而能直接看模型是否具备根据给定的实例进行underlying
function推理的能力。</p>
<p>实验发现，当问题比较简单时（系数是[1,-1]），Yi-34B和LLAMA-70B效果比较好（看下图）。</p>
<p>当问题更复杂点（系数是[1，1，1，1，1]），只有LLAMA-70B和Mistral
8*7B这样的大模型表现出了涌现的能力。</p>
<img src="/41b6a819/ict.png" class title="ICT">
<h2 id="chat模型评测">Chat模型评测</h2>
<ol type="1">
<li>自动评测</li>
</ol>
<p>评测的任务和base模型相同，分别采用zero-shot和few-shot，效果依然不错，具体结果如下</p>
<img src="/41b6a819/eval.png" class title="Yi效果">
<p>报告强调，如Goodhart’s
principle所说，当一个指标变成目标，就不再是一个好指标。因此这里的测试只是为了确认微调没有使得模型的知识能力下降，而不会专门去针对任务做优化。</p>
<p>结果上，Yi-34B-Chat数学能力不错，而Yi-6B-Chat并没有展现出强大的数学能力。推测较小的模型可能需要更多的数据在SFT阶段激活其相应的能力。</p>
<ol start="2" type="1">
<li>人工评测</li>
</ol>
<img src="/41b6a819/third_party.png" class title="三方评测">
<h1 id="能力扩展">能力扩展</h1>
<p>base模型的基础上，做了3个能力扩展：长上下文、多模态、深度扩展。</p>
<h2 id="长上下文能力">长上下文能力</h2>
<p>报告中认为，4k的base模型已经具备了长文本（200k）的能力。只要用少量数据，进行继续预训练来释放这个能力，再用轻量级的SFT来调整格式，就能获得足够好的长文本能力。</p>
<p>长文本的继续预训练中，依然使用完整的attention，而不是线性attention或者sparse
attention。</p>
<p>继续预训练的数据，混合了（1）原始预训练数据（2）length-upsampled
long-context
data长文本数据，长文本数据主要来自书籍（3）多文档问答的人造数据。</p>
<p>多文档问答数据的应答中，在最终答案之前会对和答案相关的段落进行复述（recitation），以此来提升模型长文本关联的能力。</p>
<p>这部分的数据工作主要参考《Data engineering for scaling language
models to 128k context》和《Paraphrasing the original text makes high
accuracy long-context qa》。</p>
<p>最终用了5B token的长文本数据，batch
size=4M（token），只更新了100个step（这里没明白100步是怎么来，不应该是5B/4M=1250？有没有明白的朋友指点一下）。</p>
<blockquote>
<p>We continue pretrain the model on 5B tokens with 4M batch size, which
translate to 100 optimization steps. Aligning with the concurrent work
from Fu et al. [22], we observe that such light-weight continue
pretraining is already able to enable a strong performance on
Needle-in-a-Haystack test, as we will show in Figure 6.</p>
</blockquote>
<p>这个做法与《Data engineering for scaling language models to 128k
context》一致，这样轻量级的微调已经足够在“大海捞针”任务做得很好。</p>
<p>而微调的数据，也混合了短的SFT数据，以及长的文本问答数据。</p>
<p>这些文本问答数据都是人工用模型造出来的。</p>
<p>具体的做法是，随机抽一些文档，然后从中随机选择一个或者多个段落，让一个训练好的模型根据这些段落造出问题和答案。</p>
<p>一个重要的细节是复述和改写：在给出答案之前，我们要求模型复述或改写原文段落。这种数据格式鼓励模型的检索行为，从而抑制其虚构行为：面对一个问题，模型更倾向于使用输入中的信息来构建答案，而不是使用其内部知识，后者可能与问题相关但不准确。</p>
<p>使用以上所述的轻量级训练，已经可以在“大海捞针”任务做得很好，几乎能够做到全绿。</p>
<img src="/41b6a819/long_context_result.png" class title="大海捞针效果">
<h2 id="多模态">多模态</h2>
<p>ViT部分由CLIP ViT-H/14
model初始化，后面的transformer由Yi-Chat初始化</p>
<img src="/41b6a819/multimodal.png" class title="多模态">
<p>3步训练：</p>
<p>（1）使用224^2的图像来训练ViT和projection模块的参数。这一训练利用了包含1亿个图像-文本对的数据集，这些数据来自LAION-400M。主要目标是增强ViT在架构中的知识获取能力，并实现ViT与LLM之间更好的对齐。</p>
<p>（2）将ViT的图像分辨率提升到448^2，目的是进一步推动模型识别复杂视觉细节的能力。在这个阶段使用的数据集包括从LAION-400M中提取的2000万个图像-文本对。此外，还融入了来自不同来源的大约480万个图像-文本对，例如CLLaVA、LLaVAR、Flickr、VQAv2、RefCOCO、Visual7w等。</p>
<p>（3）整个模型的参数一起训练。主要目标是提高模型在多模态聊天交互方面的熟练度，从而赋予它能够无缝融合和解释视觉与语言输入的能力。为此，训练数据集涵盖了多种来源，总共大约有100万张图像-文本对，包括GQA、VizWiz
VQA、TextCaps、OCR-VQA、Visual
Genome、ShareGPT4V等等。为了确保数据平衡，对任何单一来源的最大数据量设定了上限，将其限制在不超过50,000对。</p>
<p>使用128张A100，6B训了3天，34B训10天。</p>
<h2 id="depth-upscaling-深度扩展">Depth Upscaling 深度扩展</h2>
<p>目标是把32层的6B扩展到48层的9B模型。</p>
<p>参考《Scaling large language models with simple yet effective depth
up-scaling》，通过复制中间的12-28层共16层，把层数扩展为48层。</p>
<p>实验表明，要确定复制哪些层，可以通过测量输入和每层输出的cosine
similarity来衡量。</p>
<p>这种方法使得模型能在不额外训练的情况下，和原模型性能最接近，损失最少。</p>
<img src="/41b6a819/9B.png" class title="9B模型">
<p>这说明复制的这些层并不会很大地改变原模型的激活值。</p>
<p>除了层数增加，Depth Upscaling还要做继续预训练，才能提升效果。</p>
<p>继续预训练使用约800B token，训练过程分为两个阶段。</p>
<p>其中约70%的数据是最近收集并精心挑选的。在最后阶段增强了代码的比例以提高代码性能。</p>
<p>训练保持constant lr = 3e-5，并在模型损失达到平台期时，从4M
token开始逐渐增加batch size大小。</p>
<p>这种增加batch
size的方法，以及保持所有其他参数与Yi-6B基础模型配置一致，继续预训练很重要。</p>
<hr>
<p>读到这了，来一发点赞收藏关注吧~</p>
<p>博客：<a target="_blank" rel="noopener" href="http://www.linsight.cn/">http://www.linsight.cn/</a><br>
知乎：<a target="_blank" rel="noopener" href="https://www.zhihu.com/people/us4ever">Linsight</a><br>
微信公众号：Linsight<br>
<img src="/images/qrcode.jpg"></p>
<hr>
<p>往期文章</p>
<p><a target="_blank" rel="noopener" href="http://www.linsight.cn/6a40bfa5.html">transformer中normalization的二三事</a></p>
<p><a target="_blank" rel="noopener" href="http://www.linsight.cn/c61d17e3.html">稀疏注意力计算:sliding
window attention</a></p>
<p><a target="_blank" rel="noopener" href="http://www.linsight.cn/3dc22f96.html">理解Attention:从起源到MHA,MQA和GQA</a></p>
<p><a target="_blank" rel="noopener" href="http://www.linsight.cn/c4da56c0.html">LLM长上下文的问题</a></p>
<p><a target="_blank" rel="noopener" href="http://www.linsight.cn/a051710f.html">理解LLM位置编码:RoPE</a></p>
<p><a target="_blank" rel="noopener" href="http://www.linsight.cn/3345028a.html">大模型算法题(1)</a></p>
<p><a target="_blank" rel="noopener" href="http://www.linsight.cn/ad0bba9d.html">大模型算法题(2)</a></p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>Lin
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://saicat.github.io/41b6a819.html" title="Yi技术报告-划重点看细节">https://saicat.github.io/41b6a819.html</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/" rel="tag"><i class="fa fa-tag"></i> 多模态</a>
              <a href="/tags/NLP/" rel="tag"><i class="fa fa-tag"></i> NLP</a>
              <a href="/tags/transformer/" rel="tag"><i class="fa fa-tag"></i> transformer</a>
              <a href="/tags/LLM/" rel="tag"><i class="fa fa-tag"></i> LLM</a>
              <a href="/tags/%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87/" rel="tag"><i class="fa fa-tag"></i> 长上下文</a>
              <a href="/tags/%E6%8A%80%E6%9C%AF%E6%8A%A5%E5%91%8A/" rel="tag"><i class="fa fa-tag"></i> 技术报告</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/ad0bba9d.html" rel="prev" title="大模型算法题(2)">
                  <i class="fa fa-angle-left"></i> 大模型算法题(2)
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/44e38c1b.html" rel="next" title="MoE模型的前世今生">
                  MoE模型的前世今生 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Lin</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">601k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">18:12</span>
  </span>
</div>
<div class="busuanzi-count">
</div>

<!--
-->


<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("03/01/2023 10:00:00"); //此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒.";
    }
setInterval("createtime()",250);
</script>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.28/fancybox/fancybox.umd.js" integrity="sha256-ytMJGN3toR+a84u7g7NuHm91VIR06Q41kMWDr2pq7Zo=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>




  <script src="/js/third-party/fancybox.js"></script>



  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"ams","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"Saicat/comment-utterance","issue_term":"pathname","theme":"github-light"}</script>
<script src="/js/third-party/comments/utterances.js"></script>

</body>
</html>
